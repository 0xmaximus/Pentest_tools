import argparse
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse

def fuzz_urls(input_file, output_file):
    with open(input_file, 'r') as f:
        urls = f.readlines()

    modified_urls = []
    for url in urls:
        url = url.strip()
        parsed_url = urlparse(url)
        path_parts = parsed_url.path.split('/')
        for i, part in enumerate(path_parts):
            if part != '':
                path_parts[i] = 'FUZZ'
                modified_path = '/'.join(path_parts)
                modified_url = urlunparse(parsed_url._replace(path=modified_path))
                modified_urls.append(modified_url)
                path_parts = parsed_url.path.split('/')
                
    for url in urls:
        url = url.strip()
        parsed_url = urlparse(url)
        query_parts = parsed_url.query.split('=')
        for i, part in enumerate(query_parts):
            if part != '':
                query_parts[i] = 'FUZZ'
                modified_path = '='.join(query_parts)
                modified_url = urlunparse(parsed_url._replace(query=modified_path))
                modified_urls.append(modified_url)
                path_parts = parsed_url.path.split('=')

    with open(output_file, 'w') as f:
        f.write('\n'.join(modified_urls))

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-l', '--input_file', help='Input file containing URLs')
    parser.add_argument('-o', '--output_file', help='Output file to save modified URLs')
    args = parser.parse_args()

    fuzz_urls(args.input_file, args.output_file)
